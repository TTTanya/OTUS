{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'stellargraph'...\n",
      "Updating files:  93% (367/394)\n",
      "Updating files:  94% (371/394)\n",
      "Updating files:  95% (375/394)\n",
      "Updating files:  96% (379/394)\n",
      "Updating files:  97% (383/394)\n",
      "Updating files:  98% (387/394)\n",
      "Updating files:  99% (391/394)\n",
      "Updating files: 100% (394/394)\n",
      "Updating files: 100% (394/394), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/stellargraph/stellargraph.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import stellargraph as sg\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import Node2Vec, link_classification, GraphSAGE\n",
    "from stellargraph.data import BiasedRandomWalk, EdgeSplitter, UniformRandomWalk, UnsupervisedSampler\n",
    "from stellargraph.mapper import  Node2VecLinkGenerator, Node2VecNodeGenerator\n",
    "from stellargraph.mapper import  GraphSAGENodeGenerator, GraphSAGELinkGenerator\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание - Предсказание уровня экспресси белка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.researchgate.net/publication/313504607/figure/fig3/AS:459880453677066@1486655453033/Protein-protein-interaction-PPI-network-of-DEGs-by-STRING-The-interaction-score-was.png'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Про биологию</b>\n",
    "    \n",
    "Экспрессия — процесс, в ходе которого наследственная информация от гена (последовательности нуклеотидов ДНК) преобразуется в функциональный продукт — белок. Уровнем экспрессии называют - количество белка, производящегося в этом процессе. Чем выше экспрессия белка, тем большее количество этого белка появляется в клетках человека. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">    \n",
    "<b>Важность задачи</b>\n",
    "    \n",
    "Существует множество причин необходимости в знании уровня экспресии белка. Например - это позволяет ученым разрабатывать лекарственные средства и оптимизировать их разработку. Теперь вам предстоит побыть в роли биоинформатика и помочь науке!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Про Датасет</b>\n",
    "    \n",
    "Датасет представляет собой граф взаимойдествия белков. Где узлы это белки, взаимодействие между белками это ребро. \n",
    "\n",
    "Для каждого белка известен уровень его экспрессии. Ниже приведен список ребер `edges`. Информация по экспрессии белков, разбитая на `train` и `test`.\n",
    "   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>344</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>344</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_1  node_2\n",
       "0     344      50\n",
       "1     344     153\n",
       "2     344     532\n",
       "3     344     679\n",
       "4     344     986"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Список ребер графа \n",
    "\n",
    "edges = pd.read_csv(\"https://raw.githubusercontent.com/a-milenkin/Otus_HW_protein_expression/main/edges.csv\", sep=\",\") # Подгрузим данные\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251968</td>\n",
       "      <td>11142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689541</td>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.678245</td>\n",
       "      <td>15514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272500</td>\n",
       "      <td>20944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248888</td>\n",
       "      <td>8721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target   node\n",
       "0  0.251968  11142\n",
       "1  0.689541   2243\n",
       "2  0.678245  15514\n",
       "3  0.272500  20944\n",
       "4  0.248888   8721"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Подгрузим тренирочную выборку\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/a-milenkin/Otus_HW_protein_expression/main/train.csv\", sep=\",\") # Подгрузим данные\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.279231</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.380795</td>\n",
       "      <td>9574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.686527</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.303594</td>\n",
       "      <td>4782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.367374</td>\n",
       "      <td>24125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target   node\n",
       "0  0.279231    817\n",
       "1  0.380795   9574\n",
       "2  0.686527   1607\n",
       "3  0.303594   4782\n",
       "4  0.367374  24125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подгрузим отложенную выборку для валидации\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/a-milenkin/Otus_HW_protein_expression/main/test.csv\", sep=\",\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Про Задачу</b>\n",
    "    \n",
    "Вам предлагается предсказать экспрессию белков (`target`) по приведенным данным для отложенной выборки. Ответы в отложенной выборке `test` даны вам для самостоятельной валидации.\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Замечание и комментарии</b>\n",
    "    \n",
    "    \n",
    "\n",
    "По ряду причин датасет был упрощен так, чтобы выполнялись следующие условия:\n",
    "* у графа одна компонента связанности. \n",
    "* удалены слишком крупные хабы\n",
    "* плотность связей графа уменьшена\n",
    "* решить задачу можно классическими ML подходами\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Оценка результатов</b>\n",
    "    \n",
    "\n",
    "\n",
    "Оценка точности модели будет оцениваться по метрике MSE на отложенной выборке `test`\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Автор задачи</b>\n",
    "\n",
    "По всем дополнительным вопросами писать Александру Миленькину\n",
    "* Телеграмм: Alerin75infskin\n",
    "* Почта: milenkin.aa@phystech.edu\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение базовых признаков узлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = StellarGraph(edges=edges, source_column='node_1', target_column='node_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nx = nx.from_pandas_edgelist(edges, source='node_1', target='node_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем различные метрики центральности для узлов и посмотрим, какие из них дадут прирост в качестве моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree centrality - чем больше соседей у узла, тем больше значение\n",
    "degree_centrality = nx.degree_centrality(G_nx)\n",
    "degree_centrality_train = [round(degree_centrality[i], 8) for i in train['node'].tolist()]\n",
    "degree_centrality_test = [round(degree_centrality[i], 8) for i in test['node'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness_centrality - чем больше проходящих путей через узел, тем больше значение\n",
    "betweenness_centrality = nx.betweenness_centrality(G_nx)\n",
    "betweenness_centrality_train = [round(betweenness_centrality[i], 8) for i in train['node'].tolist()]\n",
    "betweenness_centrality_test = [round(betweenness_centrality[i], 8) for i in test['node'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closeness_centrality - чем ближе узел ко всем остальным узлам, тем больше значение\n",
    "closeness_centrality = nx.closeness_centrality(G_nx)\n",
    "closeness_centrality_train = [round(closeness_centrality[i], 8) for i in train['node'].tolist()]\n",
    "closeness_centrality_test = [round(closeness_centrality[i], 8) for i in test['node'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m community\n\u001b[0;32m      3\u001b[0m communities_generator \u001b[38;5;241m=\u001b[39m community\u001b[38;5;241m.\u001b[39mgirvan_newman(G_nx)\n\u001b[1;32m----> 5\u001b[0m top_level_communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommunities_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m next_level_communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(communities_generator)\n\u001b[0;32m      7\u001b[0m communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28msorted\u001b[39m, next_level_communities))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\community\\centrality.py:147\u001b[0m, in \u001b[0;36mgirvan_newman\u001b[1;34m(G, most_valuable_edge)\u001b[0m\n\u001b[0;32m    145\u001b[0m g\u001b[38;5;241m.\u001b[39mremove_edges_from(nx\u001b[38;5;241m.\u001b[39mselfloop_edges(g))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m g\u001b[38;5;241m.\u001b[39mnumber_of_edges() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_without_most_central_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmost_valuable_edge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\community\\centrality.py:166\u001b[0m, in \u001b[0;36m_without_most_central_edges\u001b[1;34m(G, most_valuable_edge)\u001b[0m\n\u001b[0;32m    164\u001b[0m num_new_components \u001b[38;5;241m=\u001b[39m original_num_components\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m num_new_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m original_num_components:\n\u001b[1;32m--> 166\u001b[0m     edge \u001b[38;5;241m=\u001b[39m \u001b[43mmost_valuable_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     G\u001b[38;5;241m.\u001b[39mremove_edge(\u001b[38;5;241m*\u001b[39medge)\n\u001b[0;32m    168\u001b[0m     new_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(nx\u001b[38;5;241m.\u001b[39mconnected_components(G))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\community\\centrality.py:138\u001b[0m, in \u001b[0;36mgirvan_newman.<locals>.most_valuable_edge\u001b[1;34m(G)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the edge with the highest betweenness centrality\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03min the graph `G`.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# We have guaranteed that the graph is non-empty, so this\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# dictionary will never be empty.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m betweenness \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_betweenness_centrality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(betweenness, key\u001b[38;5;241m=\u001b[39mbetweenness\u001b[38;5;241m.\u001b[39mget)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 16:4\u001b[0m, in \u001b[0;36margmap_edge_betweenness_centrality_13\u001b[1;34m(G, k, normalized, weight, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m splitext\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_random_state, create_py_random_state\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:233\u001b[0m, in \u001b[0;36medge_betweenness_centrality\u001b[1;34m(G, k, normalized, weight, seed)\u001b[0m\n\u001b[0;32m    231\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m _single_source_dijkstra_path_basic(G, s, weight)\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# accumulation\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m     betweenness \u001b[38;5;241m=\u001b[39m \u001b[43m_accumulate_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbetweenness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# rescaling\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m G:  \u001b[38;5;66;03m# remove nodes to only return edges\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:352\u001b[0m, in \u001b[0;36m_accumulate_edges\u001b[1;34m(betweenness, S, P, sigma, s)\u001b[0m\n\u001b[0;32m    350\u001b[0m         betweenness[(w, v)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         betweenness[(v, w)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    353\u001b[0m     delta[v] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m!=\u001b[39m s:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# была идея добавить признак принадлежности узла к тому или иному сообществу, но код не выполнился даже через 3 дня\n",
    "\n",
    "#from networkx.algorithms import community\n",
    "\n",
    "#communities_generator = community.girvan_newman(G_nx)\n",
    "\n",
    "#top_level_communities = next(communities_generator)\n",
    "#next_level_communities = next(communities_generator)\n",
    "#communities = sorted(map(sorted, next_level_communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = {'method': [], 'MSE': []} # датасет для сравнения mse по каждому из методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_add_metrics(method, mse):\n",
    "    df_metrics['method'] += [method]\n",
    "    df_metrics['MSE'] += [round(mse, 3)]\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение№1 - Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "emb_size = 128\n",
    "walk_number = 10\n",
    "walk_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(G, n=walk_number, length=walk_length, p=0.5, q=2.0) # определяем параметры случайных блужданий\n",
    "unsupervised_samples = UnsupervisedSampler(G, nodes=list(G.nodes()), walker=rw) # трансформирование результатов случайных блужданий в выборки вида \"id узла 1 - id узла 2 - есть связь или нет\"\n",
    "# ВОПРОС: могут ли в unsupervised_samples быть связи между узлами, несвязанными напрямую? То есть получается, что если два узла появляются в контексте одного блуждания, они являются связанными?\n",
    "\n",
    "generator = Node2VecLinkGenerator(G, batch_size) # генератор для прогнозирования наличия или отсутствия связей между узлами\n",
    "node2vec = Node2Vec(emb_size, generator=generator) # смысл модели node2vec - узлы, находящиеся близко в графе, должны иметь схожие эмбеддинги, и нужно подобрать такие параметры эмбеддингов, чтобы наилучшим образом решалась задача классификации связей между узлами\n",
    "x_inp, x_out = node2vec.in_out_tensors() # возвращаются входные векторы двух узлов (x_inp) и их эмбеддинги (x_out)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'reshape_2')>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "prediction = link_classification(output_dim=1, output_act='sigmoid', edge_embedding_method='dot')(x_out) # функция (слой нейронки), которая уже по эмбеддингам двух узлов в результате их аггрегации предсказывает, есть ли связь между ними (то есть prediction вида 0 или 1) \n",
    "model = keras.Model(inputs=x_inp, outputs=prediction) # модель, на вход которой подаются id двух узлов, а на выходе 0 или 1\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.binary_crossentropy) # параметры оптимизации модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12500/12500 [==============================] - 407s 32ms/step - loss: 0.7348\n",
      "Epoch 2/2\n",
      "12500/12500 [==============================] - 448s 36ms/step - loss: 0.7526\n",
      "CPU times: total: 1h 14min 51s\n",
      "Wall time: 17min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(generator.flow(unsupervised_samples), epochs=epochs, verbose=1, shuffle=True)\n",
    "# модель подбирает веса для наилучшшего представления эмбеддингов двух узлов, чтобы получился искомый predicition?\n",
    "# ВОПРОС: получается, что эмбеддинги в x_out - это какие-то изначальные представления узлов, а задача модели в том, чтобы их наилучшим образом перетрансформировать под задачу классификации? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_3')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь вообще не очень понятно, что происходит, где здесь используются результаты предыдущей модели model?\n",
    "x_inp_src = x_inp[0]\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src) # модель, которая по id узла выдает его эмбеддинг, вопрос, почему эта модель не обучается, как она это просто выдает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  344 27073 17468 ... 11542 20708  1185]\n"
     ]
    }
   ],
   "source": [
    "print(G.nodes().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 128)\n"
     ]
    }
   ],
   "source": [
    "node_gen_train = Node2VecNodeGenerator(G, batch_size).flow([a for a in train['node'].values]) # генератор для решения задачи классификации узлов, подается список узлов\n",
    "node_embeddings_train = np.row_stack([embedding_model.predict(b[0], verbose=0) for b in node_gen_train]) # модель предсказывает эмбеддинги для каждого узла\n",
    "print(node_embeddings_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 128)\n"
     ]
    }
   ],
   "source": [
    "node_gen_test = Node2VecNodeGenerator(G, batch_size).flow([a for a in test['node'].values])\n",
    "node_embeddings_test = np.row_stack([embedding_model.predict(b[0], verbose=0) for b in node_gen_test])\n",
    "print(node_embeddings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37047124,  0.40225986, -0.36509988, -0.551221  , -0.33363846,\n",
       "        0.03577701,  0.7108227 ,  0.37107694, -0.6011538 ,  0.19487159,\n",
       "       -0.39022028, -0.6150001 , -0.21881334, -0.7961887 ,  0.42601338,\n",
       "        0.11953713,  0.78667104,  0.71261764,  0.36819306,  0.8995808 ,\n",
       "       -0.03337247,  0.2667061 , -0.19468747,  0.357742  , -0.07335925,\n",
       "        0.94272536, -0.66263896,  0.23686177, -0.4668501 , -0.10128147,\n",
       "       -0.37212694, -0.21456368,  0.9551181 ,  0.6276452 ,  1.1120037 ,\n",
       "       -0.32135385, -0.63197875, -0.22613822, -0.32825536,  0.73370016,\n",
       "       -0.6087741 ,  0.905746  , -0.15506123, -0.02499713, -0.5758703 ,\n",
       "        0.5401822 , -0.05734826,  0.47034052,  0.566748  ,  0.588192  ,\n",
       "       -0.21350044, -0.7962067 ,  0.4040464 , -0.6956961 ,  0.5128672 ,\n",
       "        0.63982487, -0.79054177,  0.7968507 , -0.29668894, -0.574168  ,\n",
       "        0.5183935 , -0.9071786 ,  0.6027369 , -0.55443716,  0.9523302 ,\n",
       "        0.79611266, -0.88880676,  0.99493665, -0.60083437, -0.51016194,\n",
       "        0.24443077,  0.94610435,  0.76295453, -0.58007914, -0.16547114,\n",
       "        0.6835482 , -0.20470566,  0.41309977,  0.57341856, -0.5476332 ,\n",
       "        0.25413662,  0.41251865,  0.36444795,  0.02357267,  0.5365226 ,\n",
       "       -0.34471396,  0.65854996, -0.31568784,  0.5930083 , -0.47571   ,\n",
       "       -0.6233936 ,  0.2849687 ,  0.85834116,  0.2659814 , -0.20863426,\n",
       "       -0.51802194,  0.428005  , -0.0951515 ,  0.05849141,  0.60589916,\n",
       "        0.2619139 , -0.15484636,  0.31451684, -0.39298654, -0.125663  ,\n",
       "       -0.25638878, -0.5792597 ,  1.0276467 ,  0.6047468 , -0.35709736,\n",
       "        0.54344666, -0.89779586,  0.7946702 , -0.47571552, -0.8253183 ,\n",
       "       -0.8379043 ,  0.8626452 ,  0.4721871 , -0.85748225, -1.1577146 ,\n",
       "        0.695629  ,  0.14827587,  0.10226194,  0.98634833, -0.01772527,\n",
       "       -0.71523625,  0.80664146,  0.7965937 ], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8039469666013713\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(node_embeddings_train, train['target']) # обучаем любую модель регрессии по входным данным эмббединг узла - экспрессия белка\n",
    "Y_pred = rf.predict(node_embeddings_test)\n",
    "df_metrics = function_add_metrics('node2vec_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024299923212626095\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "node_embeddings_dc_train = [np.append(i, degree_centrality_train[k]) for k, i in enumerate(node_embeddings_train)]\n",
    "node_embeddings_dc_test = [np.append(i, degree_centrality_test[k]) for k, i in enumerate(node_embeddings_test)]\n",
    "\n",
    "rf.fit(node_embeddings_dc_train, train['target']) # добавили признак degree_centrality\n",
    "Y_pred = rf.predict(node_embeddings_dc_test)\n",
    "df_metrics = function_add_metrics('node2vec_degree_centrality_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03644316877214989\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "node_embeddings_bc_train = [np.append(i, betweenness_centrality_train[k]) for k, i in enumerate(node_embeddings_train)]\n",
    "node_embeddings_bc_test = [np.append(i, betweenness_centrality_test[k]) for k, i in enumerate(node_embeddings_test)]\n",
    "\n",
    "rf.fit(node_embeddings_bc_train, train['target']) # добавили признак betweenness_centrality\n",
    "Y_pred = rf.predict(node_embeddings_bc_test)\n",
    "df_metrics = function_add_metrics('node2vec_betweenness_centrality_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06886534777743225\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "node_embeddings_cc_train = [np.append(i, closeness_centrality_train[k]) for k, i in enumerate(node_embeddings_train)]\n",
    "node_embeddings_cc_test = [np.append(i, closeness_centrality_test[k]) for k, i in enumerate(node_embeddings_test)]\n",
    "\n",
    "rf.fit(node_embeddings_cc_train, train['target']) # добавили признак closeness_centrality\n",
    "Y_pred = rf.predict(node_embeddings_cc_test)\n",
    "df_metrics = function_add_metrics('node2vec_closeness_centrality_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение№2 - GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "walk_number = 5\n",
    "walk_length = 10\n",
    "num_samples = [10, 5]\n",
    "layer_sizes = [50, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(10000, 0), dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.node_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [[round(degree_centrality[i], 8), round(betweenness_centrality[i], 8), round(closeness_centrality[i], 8)] for i in G.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.014801</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.422970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.449333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17468</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.395452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>0.018602</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.484190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>0.013501</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.475351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2\n",
       "344    0.014801  0.000057  0.422970\n",
       "27073  0.017202  0.000117  0.449333\n",
       "17468  0.005000  0.000017  0.395452\n",
       "12471  0.018602  0.000139  0.484190\n",
       "3125   0.013501  0.000117  0.475351"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = pd.DataFrame(features, index=G.nodes().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_feat = StellarGraph.from_networkx(G_nx, node_features=node_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4801480e-02, 5.7490000e-05, 4.2296955e-01],\n",
       "       [1.7201720e-02, 1.1685000e-04, 4.4933268e-01],\n",
       "       [5.0005000e-03, 1.6570000e-05, 3.9545184e-01],\n",
       "       ...,\n",
       "       [5.2005202e-03, 1.5740001e-05, 4.1861340e-01],\n",
       "       [5.8005801e-03, 1.8659999e-05, 4.3738243e-01],\n",
       "       [5.1005101e-03, 1.0690000e-05, 4.5342827e-01]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_feat.node_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koren\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "unsupervised_samples = UnsupervisedSampler(G_feat, nodes=list(G_feat.nodes()), length=walk_length, number_of_walks=walk_number)\n",
    "generator = GraphSAGELinkGenerator(G_feat, batch_size, num_samples)\n",
    "graphsage = GraphSAGE(layer_sizes, generator=generator, bias=True) # смысл модели grapsage - подобрать такие параметры аггрегации признаков соседних узлов и эмбеддингов узлов, чтобы наилучшим образом решалась задача классификации связей между узлами\n",
    "x_inp, x_out = graphsage.in_out_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "prediction = link_classification(output_dim=1, output_act='sigmoid', edge_embedding_method='ip')(x_out) \n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14063/14063 [==============================] - 1361s 97ms/step - loss: 0.7170\n",
      "Epoch 2/2\n",
      "14063/14063 [==============================] - 1315s 93ms/step - loss: 0.7070\n",
      "CPU times: total: 49min 45s\n",
      "Wall time: 45min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(generator.flow(unsupervised_samples), epochs=epochs, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 10, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, 50, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 10, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 50, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 1, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " reshape_32 (Reshape)           (None, 1, 10, 3)     0           ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_33 (Reshape)           (None, 10, 5, 3)     0           ['input_25[0][0]']               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 1, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " reshape_36 (Reshape)           (None, 1, 10, 3)     0           ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_37 (Reshape)           (None, 10, 5, 3)     0           ['input_28[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 1, 3)         0           ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 1, 10, 3)     0           ['reshape_32[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 10, 3)        0           ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 10, 5, 3)     0           ['reshape_33[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 1, 3)         0           ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 1, 10, 3)     0           ['reshape_36[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 10, 3)        0           ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 10, 5, 3)     0           ['reshape_37[0][0]']             \n",
      "                                                                                                  \n",
      " mean_aggregator_6 (MeanAggrega  multiple            200         ['dropout_37[0][0]',             \n",
      " tor)                                                             'dropout_36[0][0]',             \n",
      "                                                                  'dropout_39[0][0]',             \n",
      "                                                                  'dropout_38[0][0]',             \n",
      "                                                                  'dropout_43[0][0]',             \n",
      "                                                                  'dropout_42[0][0]',             \n",
      "                                                                  'dropout_45[0][0]',             \n",
      "                                                                  'dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_34 (Reshape)           (None, 1, 10, 50)    0           ['mean_aggregator_6[1][0]']      \n",
      "                                                                                                  \n",
      " reshape_38 (Reshape)           (None, 1, 10, 50)    0           ['mean_aggregator_6[3][0]']      \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 1, 50)        0           ['mean_aggregator_6[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 1, 10, 50)    0           ['reshape_34[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 1, 50)        0           ['mean_aggregator_6[2][0]']      \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 1, 10, 50)    0           ['reshape_38[0][0]']             \n",
      "                                                                                                  \n",
      " mean_aggregator_7 (MeanAggrega  (None, 1, 50)       2550        ['dropout_41[0][0]',             \n",
      " tor)                                                             'dropout_40[0][0]',             \n",
      "                                                                  'dropout_47[0][0]',             \n",
      "                                                                  'dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_35 (Reshape)           (None, 50)           0           ['mean_aggregator_7[0][0]']      \n",
      "                                                                                                  \n",
      " reshape_39 (Reshape)           (None, 50)           0           ['mean_aggregator_7[1][0]']      \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 50)           0           ['reshape_35[0][0]',             \n",
      "                                                                  'reshape_39[0][0]']             \n",
      "                                                                                                  \n",
      " link_embedding_4 (LinkEmbeddin  (None, 1)           0           ['lambda_3[0][0]',               \n",
      " g)                                                               'lambda_3[1][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1)            0           ['link_embedding_4[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_40 (Reshape)           (None, 1)            0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,750\n",
      "Trainable params: 2,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp_src = x_inp[0::2] #ВОПРОС: почему берется не x_inp[0], а x_inp[0::2]?\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 50)\n"
     ]
    }
   ],
   "source": [
    "node_gen_train = GraphSAGENodeGenerator(G_feat, batch_size, num_samples).flow([a for a in train['node'].values])\n",
    "node_embeddings_train = np.row_stack([embedding_model.predict(b[0], verbose=0) for b in node_gen_train])\n",
    "print(node_embeddings_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50)\n"
     ]
    }
   ],
   "source": [
    "node_gen_test = GraphSAGENodeGenerator(G_feat, batch_size, num_samples).flow([a for a in test['node'].values])\n",
    "node_embeddings_test = np.row_stack([embedding_model.predict(b[0], verbose=0) for b in node_gen_test])\n",
    "print(node_embeddings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03225483,  0.02726044,  0.13855854, ...,  0.05831769,\n",
       "         0.0185952 ,  0.1042701 ],\n",
       "       [-0.16371809,  0.04585166,  0.10159466, ..., -0.00919825,\n",
       "         0.0498893 ,  0.08238328],\n",
       "       [-0.4280258 ,  0.14900573,  0.1258986 , ...,  0.02780342,\n",
       "        -0.12011281, -0.07667533],\n",
       "       ...,\n",
       "       [ 0.12050819, -0.12060038, -0.10879087, ...,  0.11193641,\n",
       "        -0.00743191,  0.14440128],\n",
       "       [-0.05559229, -0.0648063 , -0.10359725, ...,  0.16485873,\n",
       "        -0.08172357,  0.12803346],\n",
       "       [-0.07918573,  0.08120842,  0.11340284, ...,  0.0609542 ,\n",
       "         0.03742252,  0.22922885]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01576652577507869\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(node_embeddings_train, train['target']) # обучаем любую модель регрессии по входным данным эмббединг узла - экспрессия белка\n",
    "Y_pred = rf.predict(node_embeddings_test)\n",
    "df_metrics = function_add_metrics('graphsage_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение№3 - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(G, n=walk_number, length=walk_length, p=0.5, q=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = rw.run(nodes=list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_walks = [[str(a) for a in b] for b in walks] # считаем, что каждое блуждание - это некоторый \"текст\", где токены - это узлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(str_walks, vector_size=50, workers=3) # каждый узел кодируется эмбеддингом размера 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_train = np.stack([model.wv[str(a)] for a in train['node'].values]) # получаем эмбеддинги для каждого узла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_test = np.stack([model.wv[str(a)] for a in test['node'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00877515, -0.04256485,  0.01174157, ..., -0.11223593,\n",
       "         0.05709378,  0.18553546],\n",
       "       [-0.00419964, -0.09361814,  0.04775286, ..., -0.25761497,\n",
       "         0.13223149,  0.41730443],\n",
       "       [-0.01185365, -0.07294144,  0.09714877, ..., -0.29331705,\n",
       "         0.15621929,  0.45000085],\n",
       "       ...,\n",
       "       [-0.01458532, -0.04289096,  0.06652514, ..., -0.19667906,\n",
       "         0.09996622,  0.27759495],\n",
       "       [-0.03885319, -0.07478883,  0.08752935, ..., -0.2931588 ,\n",
       "         0.15089116,  0.42845595],\n",
       "       [-0.00140917, -0.06446022,  0.0115719 , ..., -0.1527885 ,\n",
       "         0.06095127,  0.21689488]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16468123893106504\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(node_embeddings_train, train['target']) # обучаем любую модель регрессии по входным данным эмббединг узла - экспрессия белка\n",
    "Y_pred = rf.predict(node_embeddings_test)\n",
    "df_metrics = function_add_metrics('word2vec_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01934439670670096\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "node_embeddings_dc_train = [np.append(i, degree_centrality_train[k]) for k, i in enumerate(node_embeddings_train)]\n",
    "node_embeddings_dc_test = [np.append(i, degree_centrality_test[k]) for k, i in enumerate(node_embeddings_test)]\n",
    "\n",
    "rf.fit(node_embeddings_dc_train, train['target']) # добавили признак degree_centrality\n",
    "Y_pred = rf.predict(node_embeddings_dc_test)\n",
    "df_metrics = function_add_metrics('word2vec_degree_centrality_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019854026110661345\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "node_embeddings_bc_train = [np.append(i, betweenness_centrality_train[k]) for k, i in enumerate(node_embeddings_train)]\n",
    "node_embeddings_bc_test = [np.append(i, betweenness_centrality_test[k]) for k, i in enumerate(node_embeddings_test)]\n",
    "\n",
    "rf.fit(node_embeddings_bc_train, train['target']) # добавили признак betweenness_centrality\n",
    "Y_pred = rf.predict(node_embeddings_bc_test)\n",
    "df_metrics = function_add_metrics('word2vec_betweenness_centrality_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02993836605589177\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "node_embeddings_cc_train = [np.append(i, closeness_centrality_train[k]) for k, i in enumerate(node_embeddings_train)]\n",
    "node_embeddings_cc_test = [np.append(i, closeness_centrality_test[k]) for k, i in enumerate(node_embeddings_test)]\n",
    "\n",
    "rf.fit(node_embeddings_cc_train, train['target']) # добавили признак closeness_centrality\n",
    "Y_pred = rf.predict(node_embeddings_cc_test)\n",
    "df_metrics = function_add_metrics('word2vec_closeness_centrality_rf', mean_squared_error(test['target'], Y_pred))\n",
    "print(mean_squared_error(test['target'], Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graphsage_rf</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word2vec_degree_centrality_rf</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word2vec_betweenness_centrality_rf</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node2vec_degree_centrality_rf</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word2vec_closeness_centrality_rf</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>node2vec_betweenness_centrality_rf</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>node2vec_closeness_centrality_rf</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>word2vec_rf</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>node2vec_rf</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               method    MSE\n",
       "0                        graphsage_rf  0.016\n",
       "1       word2vec_degree_centrality_rf  0.019\n",
       "2  word2vec_betweenness_centrality_rf  0.020\n",
       "3       node2vec_degree_centrality_rf  0.024\n",
       "4    word2vec_closeness_centrality_rf  0.030\n",
       "5  node2vec_betweenness_centrality_rf  0.036\n",
       "6    node2vec_closeness_centrality_rf  0.069\n",
       "7                         word2vec_rf  0.165\n",
       "8                         node2vec_rf  0.804"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.sort_values(['MSE'], ascending=True).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Можно сделать выводы, что добавление метрик центральности для узлов значительно повышает качество предсказаний по сравнению с \"пустыми\" методами. При этом лучшие результаты показывает простая метрика, зависящая от количества соседей узла.\n",
    "### Это можно объяснить тем, что экспрессия белка может сильно зависеть от его \"популярности\" и степени связанности с другими белками"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
